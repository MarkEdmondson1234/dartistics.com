---
title: "Correlation"
---

Correlation is a number that describes how strong of a relationship there is between two variables.

In digital analytics terms, you can use it to explore relationships between web metrics to see if an influence can be inferred, but _be careful to not hastily jump to conclusions that do not account for other factors_.  

For instance, a high correlation between social shares and SEO position could mean:

* Social shares influence SEO position
* SEO position influences social shares
* Social shares and SEO position are influenced by a third factor (such as Brand strength)
* The relationship was a chance error

It is, unfortunately, pretty common to see something like the first bullet used as the sole interpretation of a correlation, which is problematic for two reasons:

* There might be other factors in play (the other bullets in the list!)
* Correlation is not _necessarily_ a sign of causation. 

But, still, correlation can be very useful: identifying that a relationship exists can be a great place to start looking for the underlying drivers of that relationship which, ultimately, can lead to an insight than can drive an action!

## Performing correlation analysis in R

The base function `cor()` will perform correlations on a `data.frame`. Let's give this a go with some data. 

_This example requires having a `web_data` data frame. You can either load up some sample data by completing the [I/O Exercise](exercise2-io.html) (which is what is shown in the details below), or, if you have access to a Google Analytics account, you can use your own data by following the steps on the [Google Analytics API page](api-google-analytics.html)._

Once you've got some data loaded up, you should be able to enter `head(web_data)` and get something that, at least structurally, looks like this:

```{r message=FALSE, echo=FALSE}
## used for kable that makes nice RMarkdown tables
library(knitr)
web_data <- read.csv("./data/gadata_example_2.csv", stringsAsFactors = FALSE)

## get rid of first colum as it's just row numbers
web_data <- web_data[, -1]

kable(head(web_data))
```

## Let's correlate!

Correlations will only work with numeric data, so we subset to just those columns and then run the base R function `cor()` to see a correlation table:

```{r}
web_data_metrics <- web_data[,c("sessions","pageviews","entrances","bounces")]
## see correlation between all metrics
kable(cor(web_data_metrics))
```

The table is mirrored in the diagonal and provides the _correlation coefficient_ (aka, "_r_") between each pair of values that intersect in the cell. 1 means a perfect correlation, 0 means no correlation and -1 means a perfect negative correlation.

_Does the R that we're working on learning today have anything to do with the correlation coefficient _r_? Well...no. Or, at least, only to the extent that you can use R-the-platform to calculate r-the-correlation-coefficient. Good question, though!_

When working with correlations, its always a good idea to view an exploratory plot.  A handy function for this is `pairs()` which creates a scatter plot of all the metrics passed in combination:

```{r}
pairs(web_data_metrics)
```

Here you can see the correlation numbers in graphical form. For instance, the high correlation of 0.9999923 between sessions and entrances results in an almost perfect straight line.  Since a session starts with an entrance, this makes perfect sense!  A correlation of less than 1 may be a quick diagnostic that something is wrong with the tracking.

## How do web channels correlate?

One useful piece of analysis is seeing how web channels possibly interact.

### Data Prep

To get the data in the right format, the below code pivots via the `reshape2` package:

```{r message=FALSE}
## Use tidyverse to pivot the data
library(dplyr)
library(tidyr)

## Get only desktop rows, and the date, channelGrouping and sessions columns
pivoted <- web_data %>% 
  filter(deviceCategory == "desktop") %>% 
  select(date, channelGrouping, sessions) %>%
  spread(channelGrouping, sessions)

## Get rid of any NA's and replace with 0
pivoted[is.na(pivoted)] <- 0

kable(head(pivoted))
```

Take a minute to examine what the `pivoted` data looks like? Is it tidy data? Not exactly. But, that's good! In one since, we've got separate "metrics" for each day now -- the channelGrouping-sessions combination. 

### Examining the Data

We can plot and correlate all the metrics for an overview. Because we don't want to do _exactly_ the same thing as we did earlier (where's the fun in that?!), let's go ahead and round the correlation coefficients to two decimal places using the `round()` function. Other than that, we'll do exactly what we already did when we were simply correlating the metrics in our data set:

```{r}
## can't include the date as its not numeric, so remove
cor_data <- pivoted[, -1]
## not including first column, so -1 subset
cor_table <- round(cor(cor_data),2)
kable(cor_table)

pairs(cor_data)
```

### Analysis

Now, when we compare channels, we see much looser correlations for this dataset, which makes sense, right?  Correlations under 0.3 are, as a rule-of-thumb, not worth considering, so the standouts look to be **Social** vs. **Video* and **Paid** vs. **Organic Search**.

Plotting those channels, we can examine the trends to see the shape of the data

> Correlation has help us zero in on possibly interesting relationships


```{r}
library(ggplot2)
gg <- ggplot(data = pivoted) + 
      theme_minimal() + 
      ggtitle("Paid (blue) vs Organic (green) search")
gg <- gg + 
      geom_line(aes(x = as.Date(date), y = `Paid Search`), col = "blue")

gg + geom_line(aes(x = as.Date(date), y = `Organic Search`), col = "green")
```

We can see here the trends do look similar, but with a paid search peak in the first quarter (as we look at this, we might want to consider these spikes as outliers -- either simply by the visual or using a more defined method for detecting outliers; it would be quite simple to remove this data from the data set and run the analysis again...but we're not going to go down that particular rabbit hole right now).

```{r}
library(ggplot2)
gg <- ggplot(data = pivoted) + 
              theme_minimal() + 
              ggtitle("Social (red) vs Video (orange)")
gg <- gg + 
      geom_line(aes(x = as.Date(date), y = Social), col = "red")
gg + geom_line(aes(x = as.Date(date), y = Video), col = "orange")
```

Here, a peak in **Social** late in the year looks to have coincided with a peak in *Video*: possibly a campaign driving video views?

## Cross correlation

The correlations, above all, compare the same date point, but what if you expect a lagged effect?  Perhaps the video traffic drove social traffic later on due to client advocacy?

Cross correlations are useful when dealing with time-series data and can examine if a metric has an influence on itself or another after some time has passed.  

This can be a powerful way to find if, say, a TV or Display campaign increased SEO traffic over the course of the few weeks following the campaign.

The below compares paid search on SEO using the `ccf()` function. The result is the correlation for different lags of days. We can see a correlation at 0 lag at around 0.5, but the correlation increases if you lag the Social trend up to 10 days before. 

```{r}
ccf(pivoted$Social, pivoted$Video)
```

You could then conclude that Video was having a lagged effect on Social traffic up to 10 days beforehand. But, beware! The nature of cross-correlation is that if both datasets have a similar looking spike, cross-correlation will highlight it.  Careful examination of the raw data trends should be performed to verify it.  In some cases a smoother line will help get rid of spikes that affect the data (e.g., do the analysis on weekly or monthly data instead of daily). And, of course, there is no substitue for rational thought: if you find a relationship like this, can you explain it rationally? And, if so, can you conduct further analysis to validate that rationalization? _(If only R had an **Easy Button** to do the actual thinking, too. Alas!)_