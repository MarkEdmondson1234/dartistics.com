---
title: "Day 2 in R"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
```

## Load the data

We download the data used for the statistics class:

```{r}
raw_data <- "sampleStatsData.csv"
if(!file.exists(raw_data)){
  download.file("https://raw.githubusercontent.com/MarkEdmondson1234/dartistics.com/master/sampleStatsData.csv", 
              destfile = raw_data)
}

all_data <- read.csv(raw_data, stringsAsFactors = FALSE)

small_data <- all_data %>% 
          select(date, deviceCategory, channelGrouping, Sessions, GoalCompletions)
knitr::kable(head(small_data))
summary(small_data)
```

## First plot to find shape of the data

```{R}
all_data$date <- as.Date(all_data$date)
overall_data <- all_data %>% 
  select(date, deviceCategory, channelGrouping, Sessions) %>% 
  mutate(yearMonth = format(date, format = "%Y%m")) %>% 
  group_by(yearMonth) %>% 
  summarise(sessionSum = sum(Sessions))

plot(overall_data, type = "l")

## a ggplot version
library(ggplot2)
gg <- ggplot(overall_data, aes(yearMonth, sessionSum)) + theme_dark()
gg <- gg + geom_line(aes(group = 1))
gg + geom_vline(xintercept=c(6,10), linetype = "dotted")
```

## Splitting into Groups

The statistical analysis was carried out on three subsets of this data. (see data two content)

The three files match to the following rows:

* Group 1 (row 1 - row 4054)
* Group 2 (row 4055 - 5905)
* Group 3 (row 5906 - 7162)

We want to run analysis on these groups seperately, so we split them up into three different data frames:

```{r}
group_one <- all_data[1:4054, ]
group_two <- all_data[4055:5905, ]
group_three <- all_data[5906:7162, ]
```

Because we want to run analysis at the same time, we put those data.frames into a list.  This means we can run functions over them using `lapply`

```{r}
all_groups <- list(group_one = group_one,
                   group_two = group_two,
                   group_three = group_three)
```

## Cross Tabulation

As the result of `lapply` is always a list, you can take the result of `lapply` and use it in another:

```{r}
my_cross_table <- function(x, cross1, cross2){
  totals <- table(x[[cross1]], x[[cross2]])
  
  totals
}

result <- lapply(all_groups, 
       my_cross_table, 
       cross1 = "deviceCategory", cross2 = "channelGrouping")

result$group_one
```


## Summary statistics

We start with creating summary statistics.  One option would be to use `summary()` but `describe()` from the `psych` package as it also shows `skew` and `kurtosis`.

The output is generated via the same general workflow:

1. Create a function that will operate on one of the group data.frames (e.g `all_groups[[1]]`)
2. Run the function over the list of group data.frames
3. Analyse the result

```{R, message=FALSE, warning=FALSE}
library(psych) # statistics

my_summary <- function(x, metric){
  y <- x[, metric]

  describe(y)
}


lapply(all_groups, my_summary, metric = c("Sessions", "GoalCompletions"))

```

Note that we pass the `metric` argument via `lapply()`, which is constant for all the data passed to the functions.

### Create class statistics

To create other statistics, we need to create a new function:

```{r}
my_class_stats <- function(x, dimension){
  dim <- x[[dimension]]
  
  ## makes a dataframe of $Var1 and $Freq
  my_df <- as.data.frame(table(dim))
  sum_all <- sum(my_df$Freq)
  my_df$percent <- round(my_df$Freq / sum_all, 4)
  my_df$cum.percent <- cumsum(my_df$percent)
  
  my_df
}
```

To run the function over the different dimensions, we change the function argument:

```{r}
lapply(all_groups, my_class_stats, dimension = "deviceCategory")
lapply(all_groups, my_class_stats, dimension = "channelGrouping")
```


## Chi Squared and expected value

Here we first print out the expected values (Compare with above) and then perform a chi-squared test on if the actual values are signficantly different.

```{R, message=FALSE, warning=FALSE}
library(questionr) ## for cramerV

my_chi_table <- function(x, cross1, cross2){
  tab <- table(x[[cross1]], x[[cross2]])
  y <- chisq.test(tab)
  
  list(
    expected = y$expected,
    observed = y$observed,
    error = y$expected - y$observed,
    chi = y,
    cramerV = round(cramer.v(tab), digits = 4)
  )

}

```

#### Exercise

1. Run the Chi Squared function above over all the `data.frames` in list `all_groups` with `cross1="deviceCategory"` and `cross2="channelGrouping"`
2. What is the cramerV for Group 2?
3. A function to create a barplot of the Chi Squared result is below. Run it upon the results you got in part 1.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
my_cols <- c("#AAA81B","#77774B","#3D81AA")
plot_func <- function(x){
  barplot(x$error, 
          beside = TRUE, 
          main = "Expected - Observed", 
          sub = paste(x$chi$method, x$chi$p.value, " CramerV: ", x$cramerV),
          col = my_cols)
  legend("topright",fill=my_cols, legend=rownames(x$error))
}

```

4. Change the colours of the barplot to something you like. Try this [website for color wheels](https://color.adobe.com/create/color-wheel/).

## ANOVA

Analysis of variance - find out where is the source of the error that you identified in the chi-squared. 

### 1-Way ANOVA

By channel, do sessions differ?  Here we compare all the groups.

* Between Groups (SSx) - line 1 (`channelGrouping`)
* Within Groups (SSe) - line 2 (`Residuals`)
* F (actual) - `F value`
* The p-value of F (actual) | F (expected) - `Pr(>F)`

```{r}
my_oneway_anova <- function(x, metric, dim){
  my_form <- as.formula(paste(metric, "~", dim))
  model <- aov(my_form , data = x)
  summary(model)
}

## Sessions ~ channelGrouping
lapply(all_groups, 
       my_oneway_anova, 
       metric = "Sessions", dim = "channelGrouping")

```

### Tukey 

If it is significant, run some post-hoc results.  In this example we use Tukey (vs say Bonferroni).

This runs over each channel, for each group.  

If 0 is between the lower and upper bound then don't reject the NULL hypothesis. 

```{R}
my_oneway_anova_tukey <- function(x, metric, dim){
  my_form <- as.formula(paste(metric, "~", dim))
  model <- aov(my_form , data = x)
  TukeyHSD(model)
}

## Sessions ~ deviceCategory
my_oneway_anova_tukey_results <- lapply(all_groups, 
                                        my_oneway_anova_tukey, 
                                        metric = "Sessions", dim = "deviceCategory")
my_oneway_anova_tukey_results$group_two
```

### Multi way ANOVA

* `H0_a` the group means for first factor are equal
* `H0_b` The group means for the second factor are equal
* `H0_c` There is no interaction between the two factors

```{r}
my_nway_anova <- function(x, metric, dim){
  my_form <- as.formula(paste(metric, "~", dim))
  anova(lm(my_form , data = x))
}

## tests of between subject effects
lapply(all_groups, 
       my_nway_anova, 
       metric = "Sessions", dim = "deviceCategory * channelGrouping")
```


## Regression outputs

The basic function for calculating regression is `lm`

```
lm(dependent ~ independent, data = x)
```

The first argument is an R formula, recognised via the `~` symbol.  This is a common way for R to work more easily with statistics.

* `F statistic` - is the model significant
* `Estimate` the `B0` and `B1` of `y = B0 + B1x`
  - `(Intercept)` = `B0`
  - `Sessions` = `B1`
* `R^2` - how much is explained by the presence of the inclusion of `Sessions`

```{r}
my_models_fun <- function(x, dependent, independent){
  my_form <- as.formula(paste(dependent, "~", independent))
  model <- lm(my_form, data = x)
}

my_models <- lapply(all_groups, 
                    my_models_fun, 
                    dependent = "GoalCompletions", 
                    independent = "Sessions")

results <- lapply(my_models, summary)

results
```

### Calculating the prediction interval for mean

What to pay attention to and what to ignore.  If within this bound its within acceptable range. 

If its outside, then something significant has happened. 

This is the range of the dependent variable. (Confidence interval is of the independent variable)

```{R}
my_predict_mean <- function(x, new_value = mean(x$Sessions)){
  model <- lm(GoalCompletions ~ Sessions, data = x)
  
  
  p <- predict(model, 
          newdata = data.frame(Sessions = new_value),
          interval = "predict",
          level = 0.95)
  conf <- confint(model, level = 0.95)
  
  list(prediction.interval = p,
       confidence.interval = conf)
}

## generate the upper and lower bound for beta coefficents
lapply(all_groups, my_predict_mean)
```

### Multilinear regression

Using the dummary variables:

```{r}
multi_regression <- function(x){
  model <- lm(GoalCompletions ~ DesktopDummy + TabletDummy + Sessions, data = x)
  summary(model)
}

mr1 <- lapply(all_groups, multi_regression)
mr1$group_one
```

If you forget to leave out one of your dummy variables, its ok:

```{r}
multi_regression <- function(x){
  model <- lm(GoalCompletions ~ DesktopDummy + TabletDummy + MobileDummy + Sessions, data = x)
  summary(model)
}

mr1 <- lapply(all_groups, multi_regression)
mr1$group_one
```

Interpretation: A mobile session that was instead on desktop would be 246% more likely to convert:

```{r}
multi_regression <- function(x){
  model <- lm(GoalCompletions ~ DesktopDummy + TabletDummy + MobileDummy + Sessions, data = x)
  summary(model)
}

mr1 <- lapply(all_groups, multi_regression)
mr1$group_one
```

Repeated for channel groupings, dummy variables:

```{r}

multi_regression2 <- function(x){
  model <- lm(GoalCompletions  ~ Sessions + DirectDummy + DisplayDummy + OrganicSearchDummy + PaidSearchDummy + ReferralDummy + SocialDummy + EmailDummy, data = x)
  summary(model)
}

mr2 <- lapply(all_groups, multi_regression2)

mr2$group_one
```

When creating your model, you may consider taking out the non-significant dummy variables.

## Creating Dummy variables in R

R will attempt to use dummy variables when it can, but if you want to make your own R has some tools to help:

```{r}
head(small_data)

dummy_vars <- model.matrix(GoalCompletions ~ Sessions + deviceCategory + 0, 
                           data = small_data) 
head(cbind(data.frame(GoalCompletions = small_data$GoalCompletions), dummy_vars))
```
